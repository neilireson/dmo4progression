{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#####################################################\n",
    "# Data preparation and exclusion\n",
    "#\n",
    "#####################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import seaborn as sns\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "data_dir = os.getenv(\"DATA_DIR\", \"Dataset/\")\n",
    "min_prev_score = 0\n",
    "threshold = 5.0\n",
    "min_progression = 1.0\n",
    "\n",
    "# read in main MS dataset\n",
    "data_file_path = data_dir + r\"MS_dataset_v.7.3.csv\"\n",
    "cols_from_dataset = ['Local.Participant', 'EDFSCR1L', 'visit.number', 'age', 'gender', 'mstypeonset', 'mstypediag', 'visit.date']\n",
    "data = pd.read_csv(data_file_path, usecols=cols_from_dataset)\n",
    "\n",
    "# forward fill within groups to ensure no leakage of demographics between participants\n",
    "cols_from_dataset = [col for col in cols_from_dataset if col in ['age', 'gender', 'mstypeonset', 'mstypediag']]\n",
    "for col in cols_from_dataset:\n",
    "    data[col] = data.groupby('Local.Participant')[col].ffill()\n",
    "\n",
    "# we need to get the time difference and convert from timedelta to something that the ML models can use - probably unix time\n",
    "data['time_since_diag'] = (pd.to_datetime(data['visit.date']) - pd.to_datetime(data['mstypediag'])).dt.total_seconds()\n",
    "data['time_since_onset'] = (pd.to_datetime(data['visit.date']) - pd.to_datetime(data['mstypeonset'])).dt.total_seconds()\n",
    "\n",
    "# drop cols used for calculation\n",
    "data = data.drop(['mstypeonset', 'mstypediag', 'visit.date'], axis=1)\n",
    "\n",
    "# convert gender to 0 and 1\n",
    "data['gender'] = data['gender'].map({'Male': 0, 'Female': 1})\n",
    "\n",
    "# Crop down to just the necessary columns\n",
    "data = data.sort_values(by=['Local.Participant', 'visit.number'])\n",
    "\n",
    "# shift timepoints and EDSS to get previous as columns\n",
    "data['Prev_EDSS'] = data.groupby('Local.Participant')['EDFSCR1L'].shift(1)\n",
    "data['Prev_Timepoint'] = data.groupby('Local.Participant')['visit.number'].shift(1)\n",
    "\n",
    "# get progression label column\n",
    "progression_mask = (\n",
    "    (data['Prev_EDSS'] < threshold) &\n",
    "    (data['EDFSCR1L'] >= threshold) &\n",
    "    ((data['EDFSCR1L'] - data['Prev_EDSS']) >= min_progression)\n",
    ")\n",
    "data['progression'] = np.where(progression_mask, 1, 0)\n",
    "\n",
    "transitions = data[progression_mask]  # all the data where a transition happens, just in case.\n",
    "\n",
    "data['Prev_Timepoint'] = data['Prev_Timepoint'].str.upper()  # needed for later merges\n",
    "data['visit.number'] = data['visit.number'].str.upper()  # this one is just for consistency\n",
    "\n",
    "#display(transitions.head(10))\n",
    "\n",
    "# now that we have a reduced dataset, loop through our weekly dmo aggregations and append the relevant ones to the dataframe\n",
    "timepoints = [\"T1\", \"T2\", \"T3\", \"T4\"]  # we don't need DMOs where T5 is previous\n",
    "\n",
    "dfs_list = []\n",
    "for timepoint in timepoints:\n",
    "    feature_file_path = data_dir + f\"/{timepoint} Aggregated DMO Data_V7.3/cvs-{timepoint}-weekly_agg_all-21-01-2026.csv\"\n",
    "    temp_df = pd.read_csv(feature_file_path)\n",
    "    dfs_list.append(temp_df)\n",
    "\n",
    "features_df = pd.concat(dfs_list, ignore_index=True)\n",
    "data = pd.merge(data, features_df, left_on=['Local.Participant', 'Prev_Timepoint'],\n",
    "                right_on=['participant_id', 'visit_type'], how='left')\n",
    "\n",
    "data = data.drop(['participant_id', 'visit_type'], axis=1)\n",
    "data = data.dropna(subset=['Prev_Timepoint'])\n",
    "\n",
    "# Data cleaning - will monitor number of rows throughout\n",
    "print(f\"Initially {len(data)} rows.\")\n",
    "\n",
    "# get rid of participants where either current or previous EDSS is missing\n",
    "count_before = len(data)\n",
    "data = data.dropna(subset=['EDFSCR1L', 'Prev_EDSS'])\n",
    "print(f\"{count_before - len(data)} rows have missing EDSS values and will be dropped...\")\n",
    "\n",
    "# Create matrix of prev -> next EDSS scores\n",
    "prev_scores = data['Prev_EDSS'].to_numpy().tolist()\n",
    "next_scores = data['EDFSCR1L'].to_numpy().tolist()\n",
    "\n",
    "# extract the unique scores\n",
    "scores = list(set(prev_scores).union(set(next_scores)))\n",
    "scores.sort()\n",
    "n_scores = len(scores)\n",
    "\n",
    "# Create transition matrix\n",
    "# Note some of these transitions will be for people with missing DMOs\n",
    "transition_matrix = pd.DataFrame(\n",
    "    np.zeros((n_scores, n_scores), dtype=int),\n",
    "    index=scores,\n",
    "    columns=scores)\n",
    "\n",
    "for prev_score, next_score in zip(prev_scores, next_scores):\n",
    "    transition_matrix.loc[prev_score, next_score] += 1\n",
    "\n",
    "# Pretty print transition matrix as heatmap\n",
    "plt.subplots(figsize=(10, 8))\n",
    "ax = plt.subplot(111)\n",
    "sns.heatmap(transition_matrix.values, annot=True, cmap=\"Blues\", ax=ax, fmt='d', norm=colors.LogNorm())\n",
    "ax.set_xlabel('Next Score')\n",
    "ax.set_ylabel('Previous Score')\n",
    "ax.xaxis.set_ticklabels(scores)\n",
    "ax.yaxis.set_ticklabels(scores)\n",
    "plt.show()\n",
    "\n",
    "# Exclude participants with Prev_EDSS >= threshold as they have already progressed:\n",
    "count_before = len(data)\n",
    "high_prev_edss_mask = (data['Prev_EDSS'] >= threshold)\n",
    "print(f\"{sum(high_prev_edss_mask)} rows have a previous EDSS >= {threshold} and will be dropped...\")\n",
    "data = data.drop(data[high_prev_edss_mask].index)\n",
    "\n",
    "# Exclude participants with Prev_EDSS < min_prev_score as they are highly unlikely to progress, and may have different mobility patterns\n",
    "count_before = len(data)\n",
    "low_prev_edss_mask = (data['Prev_EDSS'] < min_prev_score)\n",
    "print(f\"{sum(low_prev_edss_mask)} rows have a previous EDSS < {min_prev_score} and will be dropped...\")\n",
    "data = data.drop(data[low_prev_edss_mask].index)\n",
    "\n",
    "# drop all remaining NAN rows, which will be due to missing DMOs\n",
    "count_before = len(data)\n",
    "data = data.dropna()\n",
    "print(f\"{count_before - len(data)} rows have missing DMOs and will be dropped...\")\n",
    "\n",
    "num_progressions = len(data[data[\"progression\"] == 1])\n",
    "unique_sub_progressions = len(data[data[\"progression\"] == 1]['Local.Participant'].unique())\n",
    "\n",
    "print(\n",
    "    f\"We have {num_progressions} progressions across {unique_sub_progressions} subjects, out of a total of {len(data)} valid samples.\")\n",
    "\n",
    "display(data[data[\"progression\"] == 1].head(5))\n",
    "\n",
    "#labels_df.to_csv(\"data.csv\", index=False)\n",
    "\n",
    "# need to be at least 1 (not 0.5) to change\n",
    "# subset of EDSS and normalise?\n",
    "# balance dataset - Done very good\n",
    "\n",
    "# undersampled_df = labels_df.groupby('progression').sample(labels_df.groupby('progression').size().min())"
   ],
   "id": "3938a14c16da2718"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "###################################################################\n",
    "# Feature selection and exclusion\n",
    "# Note that in data preparation rows with NaN values are excluded.\n",
    "# Removing these features (columns) may increase the data,\n",
    "# if that feature is the reason for NaN exclusion.\n",
    "###################################################################\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.stats import spearmanr\n",
    "from collections import defaultdict\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# ToDo Test with various thresholds 0, 0.05, 0.1\n",
    "mi_threshold = 0.0\n",
    "\n",
    "\n",
    "def rf_feature_analysis(X, y, random_state=42):\n",
    "    model = RandomForestRegressor(random_state=random_state)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # The importance of a feature is how much this feature is used in each tree of the forest.\n",
    "    # It is computed as the (normalized) total reduction of the criterion brought by that feature.\n",
    "    std = np.std([tree.feature_importances_ for tree in model.estimators_], axis=0)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    importances = pd.Series(model.feature_importances_, index=np.array(X.columns))\n",
    "    importances = pd.Series(data=importances, index=X.columns).sort_values(ascending=False)\n",
    "    importances.plot.bar(yerr=std, ax=ax)\n",
    "    ax.set_title(\"Feature importance using MDI\")\n",
    "    ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "\n",
    "def rf_perm_feature_analysis(X, y, random_state=42):\n",
    "    model = RandomForestClassifier(random_state=random_state)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    result = permutation_importance(model, X, y, n_repeats=10, random_state=random_state, n_jobs=2)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    importances = pd.Series(result.importances_mean, index=np.array(X.columns))\n",
    "    importances = pd.Series(data=importances, index=X.columns).sort_values(ascending=False)\n",
    "    importances.plot.bar(yerr=result.importances_std, ax=ax)\n",
    "    ax.set_title(\"Feature importance using permutation on full model\")\n",
    "    ax.set_ylabel(\"Mean accuracy decrease\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_permutation_importance(clf, X, y, ax, indexes=None, random_state=42):\n",
    "    result = permutation_importance(clf, X, y, n_repeats=10, random_state=random_state, n_jobs=2)\n",
    "    if indexes is not None:\n",
    "        perm_sorted_idx = indexes\n",
    "    else:\n",
    "        perm_sorted_idx = result.importances_mean.argsort()\n",
    "\n",
    "    tick_labels_dict = {\"tick_labels\": X.columns[perm_sorted_idx]}\n",
    "    ax.boxplot(result.importances[perm_sorted_idx].T, vert=False, **tick_labels_dict)\n",
    "    ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "    return ax\n",
    "\n",
    "\n",
    "def rf_combine_feature_analysis(X, y, random_state=42):\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=random_state)\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    mdi_importances = pd.Series(clf.feature_importances_, index=X.columns)\n",
    "    tree_importance_sorted_idx = np.argsort(clf.feature_importances_)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 8))\n",
    "    mdi_importances.sort_values().plot.barh(ax=ax1)\n",
    "    ax1.set_xlabel(\"Gini importance\")\n",
    "    plot_permutation_importance(clf, X, y, ax2, tree_importance_sorted_idx)\n",
    "    ax2.set_xlabel(\"Decrease in accuracy score\")\n",
    "    fig.suptitle(\n",
    "        \"Impurity-based vs. permutation importance on multicollinear features (train set)\"\n",
    "    )\n",
    "    _ = fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def mi_feature_analysis(X, y, mi_threshold=0.0, random_state=42):\n",
    "    # feature importance analysis\n",
    "    pearson_corr = X.corrwith(y).sort_values(ascending=False)\n",
    "    display(pearson_corr)\n",
    "\n",
    "    # mutual information gain for feature removal\n",
    "    mi = mutual_info_classif(X, y, random_state=random_state, n_jobs=-1)\n",
    "    mi = pd.Series(data=mi, index=X.columns).sort_values(ascending=False)\n",
    "    mi.plot(kind='bar')\n",
    "    plt.show()\n",
    "\n",
    "    # delete features with 0 information gain\n",
    "    mi = mi[mi > mi_threshold]\n",
    "\n",
    "    X = X[mi.index]\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def show_correlation(X, y):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 8))\n",
    "    corr = spearmanr(X).correlation\n",
    "\n",
    "    # Ensure the correlation matrix is symmetric\n",
    "    corr = (corr + corr.T) / 2\n",
    "    np.fill_diagonal(corr, 1)\n",
    "\n",
    "    # We convert the correlation matrix to a distance matrix before performing\n",
    "    # hierarchical clustering using Ward's linkage.\n",
    "    distance_matrix = 1 - np.abs(corr)\n",
    "    dist_linkage = hierarchy.ward(squareform(distance_matrix))\n",
    "    dendro = hierarchy.dendrogram(\n",
    "        dist_linkage, labels=X.columns.to_list(), ax=ax1, leaf_rotation=90\n",
    "    )\n",
    "    dendro_idx = np.arange(0, len(dendro[\"ivl\"]))\n",
    "\n",
    "    ax2.imshow(corr[dendro[\"leaves\"], :][:, dendro[\"leaves\"]])\n",
    "    ax2.set_xticks(dendro_idx)\n",
    "    ax2.set_yticks(dendro_idx)\n",
    "    ax2.set_xticklabels(dendro[\"ivl\"], rotation=\"vertical\")\n",
    "    ax2.set_yticklabels(dendro[\"ivl\"])\n",
    "    _ = fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return dist_linkage\n",
    "\n",
    "\n",
    "def cluster_selection(X, y, dist_linkage, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state, train_size=0.5)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=random_state)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(f\"Baseline accuracy on test data: {clf.score(X_test, y_test):.2}\")\n",
    "\n",
    "    cluster_ids = hierarchy.fcluster(dist_linkage, 1, criterion=\"distance\")\n",
    "    cluster_id_to_feature_ids = defaultdict(list)\n",
    "    for idx, cluster_id in enumerate(cluster_ids):\n",
    "        cluster_id_to_feature_ids[cluster_id].append(idx)\n",
    "    selected_features = [v[0] for v in cluster_id_to_feature_ids.values()]\n",
    "    selected_features_names = X.columns[selected_features]\n",
    "\n",
    "    X_train_sel = X_train[selected_features_names]\n",
    "    X_test_sel = X_test[selected_features_names]\n",
    "\n",
    "    clf_sel = RandomForestClassifier(n_estimators=100, random_state=random_state)\n",
    "    clf_sel.fit(X_train_sel, y_train)\n",
    "    print(\n",
    "        \"Baseline accuracy on test data with features removed:\"\n",
    "        f\" {clf_sel.score(X_test_sel, y_test):.2}\"\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    plot_permutation_importance(clf_sel, X_test_sel, y_test, ax)\n",
    "    ax.set_title(\"Permutation Importances on selected subset of features\\n(test set)\")\n",
    "    ax.set_xlabel(\"Decrease in accuracy score\")\n",
    "    ax.figure.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return X[selected_features_names]\n",
    "\n",
    "# drop irrelevant or 'cheating' columns\n",
    "y_data = data[\"progression\"].reset_index(drop=True)  # can be data[\"progression\"] or data[\"multiclass_progression\"]\n",
    "labels_X_all = data.reset_index(drop=True)\n",
    "X_data = data.drop([\"progression\", \"Local.Participant\", \"EDFSCR1L\",\n",
    "                    \"visit.number\", \"Prev_Timepoint\"], axis=1)\n",
    "\n",
    "# remove any feature with an MI pf 0\n",
    "X_after_feature_selection = mi_feature_analysis(X_data, y_data, mi_threshold=0)\n",
    "\n",
    "# rf_feature_analysis(X_data, y_data)\n",
    "# rf_perm_feature_analysis(X_data, y_data)\n",
    "rf_combine_feature_analysis(X_after_feature_selection, y_data)\n",
    "\n",
    "dist_linkage = show_correlation(X_after_feature_selection, y_data)\n",
    "X_after_feature_selection = cluster_selection(X_after_feature_selection, y_data, dist_linkage)\n",
    "\n"
   ],
   "id": "8626fbe670970d3f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# X_after_feature_selection = mi_feature_analysis(X_data, y_data, mi_threshold = mi_threshold)\n",
   "id": "eca5ca8c2551c83"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "######################################################################\n",
    "# Classification / Prediction\n",
    "# Note this needs to be tidied up into the experimentation framework\n",
    "######################################################################\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, KFold\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#import faulthandler\n",
    "#import signal\n",
    "\n",
    "#faulthandler.register(signal.SIGINT.value)\n",
    "\n",
    "# Data normalisation (Not the impact of this needs to be tested)\n",
    "# e.g. StandardScaler, MinMaxScaler, RobustScaler\n",
    "# If columns have different (e.g. skewed) distributions that may need different normalisations\n",
    "# e.g. Log normalisation\n",
    "# Note that StandardScaler combined with small data will hang SVC, MinMaxScaler works\n",
    "scaler = MinMaxScaler()\n",
    "cv_folds = 5\n",
    "do_data_sampling = False\n",
    "do_PCA = True\n",
    "\n",
    "\n",
    "def get_unsampled(x_data, x_sampled, y_data):\n",
    "    # Create dataframe with column showing whether data has been sampled or not\n",
    "    # Shown by column \"_merge\" value \"both\" == sampled \"left_only\" == not sampled\n",
    "    merged = x_data.merge(x_sampled.drop_duplicates(), how='left', indicator=True)\n",
    "    # Get indices of rows which have not been sampled\n",
    "    unsampled_indices = merged.index[merged['_merge'] == \"left_only\"].tolist()\n",
    "    X_unsampled = X_data.iloc[unsampled_indices]\n",
    "    y_unsampled = y_data.iloc[unsampled_indices]\n",
    "    return X_unsampled, y_unsampled\n",
    "\n",
    "\n",
    "def do_cv(model, X_data, y_data, n_splits=cv_folds):\n",
    "    # require set_config(transform_output=\"pandas\")\n",
    "    # transformer = ColumnTransformer([('standard_scaler', ss, feature_cols)],\n",
    "    #                                 remainder='passthrough',\n",
    "    #                                 verbose_feature_names_out=False)\n",
    "\n",
    "    combined_cm = None\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    for i, (train_split_indices, test_split_indices) in enumerate(kf.split(X_data)):\n",
    "\n",
    "        X_train_split = X_data.iloc[train_split_indices]\n",
    "        X_test_split = X_data.iloc[test_split_indices]\n",
    "        y_train_split = y_data.iloc[train_split_indices]\n",
    "        y_test_split = y_data.iloc[test_split_indices]\n",
    "\n",
    "        X_train_scaled = scaler.fit_transform(X_train_split)\n",
    "        X_test_scaled = scaler.transform(X_test_split)\n",
    "\n",
    "        # sample weighting\n",
    "        sample_weights = compute_sample_weight(class_weight='balanced', y=y_train_split)\n",
    "\n",
    "        model.fit(X_train_scaled, y_train_split, sample_weight=sample_weights)\n",
    "\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "        print(f\"Fold {i} Accuracy: {accuracy_score(y_test_split, y_pred):.2f}\")\n",
    "\n",
    "        cm = confusion_matrix(y_test_split, y_pred)\n",
    "        if combined_cm is None:\n",
    "            combined_cm = cm\n",
    "        else:\n",
    "            combined_cm = combined_cm + cm\n",
    "\n",
    "    return combined_cm\n",
    "\n",
    "\n",
    "def show_evaluation(X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "\n",
    "    plt.title('Confusion Matrix: Predicted vs. Actual')\n",
    "    plt.ylabel('Actual Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if (do_data_sampling):\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    smote = SMOTE(random_state=42)\n",
    "    adasyn = ADASYN(random_state=42)\n",
    "\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_after_feature_selection, y_data)\n",
    "else:\n",
    "    if do_PCA:\n",
    "        X_resampled = X_data # don't do feature selection if we  want to do PCA\n",
    "    else:\n",
    "        X_resampled = X_after_feature_selection\n",
    "    y_resampled = y_data\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# normalisation\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "if do_PCA:\n",
    "    pca = PCA(n_components=0.95, svd_solver='full') # keep 95% of variance\n",
    "    X_train = pd.DataFrame(data = pca.fit_transform(X_train))\n",
    "    X_test = pd.DataFrame(data = pca.transform(X_test))\n",
    "    print(\"Explained variance:\", pca.explained_variance_ratio_)\n",
    "    print(\"Cumulative:\", np.cumsum(pca.explained_variance_ratio_))\n",
    "\n",
    "# sample weighting\n",
    "sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "\n",
    "model = BayesSearchCV(\n",
    "    SVC(random_state=42),\n",
    "    {\n",
    "        'C': Real(1e-6, 1e+6, prior='log-uniform'),  # Regularization parameter\n",
    "        'gamma': Real(1e-6, 1e+1, prior='log-uniform'),  # Kernel coefficient\n",
    "        'kernel': Categorical(['rbf', 'poly', 'sigmoid']),  # Type of kernel\n",
    "        'degree': Integer(1, 5)  # Degree for poly kernel\n",
    "    },\n",
    "    n_iter=20,\n",
    "    random_state=42,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    scoring='f1'\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled, y_train, sample_weight=sample_weights)\n",
    "\n",
    "# Print the best parameters\n",
    "print(f\"Best Parameters: {model.best_params_}\")\n",
    "print(f\"Best Score: {model.best_score_}\")\n",
    "\n",
    "show_evaluation(X_test_scaled, y_test)\n",
    "\n",
    "if (do_data_sampling):\n",
    "    # Following code tests with all the data points not used in training the model\n",
    "    X_not_train, y_not_train = get_unsampled(X_data, X_train, y_data)\n",
    "    X_not_train_scaled = scaler.fit_transform(X_not_train)\n",
    "    show_evaluation(X_not_train_scaled, y_not_train)\n",
    "\n",
    "# Annoyingly cross_val_score and cross_val_predict can differ ???\n",
    "\n",
    "conf_mat = do_cv(model, X_data, y_data)\n",
    "\n",
    "# Pretty print confusion matrix\n",
    "\n",
    "ax = plt.subplot()\n",
    "\n",
    "confusion_matrix = pd.DataFrame(conf_mat, range(2), range(2))\n",
    "sns.heatmap(confusion_matrix, annot=True, cmap=\"Blues\", ax=ax, fmt='d')\n",
    "\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.xaxis.set_ticklabels(['0', '1'])\n",
    "ax.yaxis.set_ticklabels(['0', '1'])\n",
    "plt.show()"
   ],
   "id": "e618d5535611471f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = BayesSearchCV(\n",
    "    SVC(random_state=42),\n",
    "    {\n",
    "        'C': Real(1e-6, 1e+6, prior='log-uniform'),  # Regularization parameter\n",
    "        'gamma': Real(1e-6, 1e+1, prior='log-uniform'),  # Kernel coefficient\n",
    "        'kernel': Categorical(['rbf', 'poly', 'sigmoid']),  # Type of kernel\n",
    "        'degree': Integer(1, 5)  # Degree for poly kernel\n",
    "    },\n",
    "    n_iter=20,\n",
    "    random_state=42,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    scoring='f1'\n",
    ")\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp_model = BayesSearchCV(\n",
    "    MLPClassifier(random_state=42, max_iter=1000),\n",
    "    {\n",
    "        'hidden_layer_sizes': Integer(1, 128),  # Different architectures\n",
    "        'activation': Categorical(['tanh', 'relu']),\n",
    "        'solver': Categorical(['sgd', 'adam']),\n",
    "        'alpha': Real(1e-5, 1e-1, prior='log-uniform'),  # L2 penalty (regularization)\n",
    "        'learning_rate': Categorical(['constant', 'adaptive']),\n",
    "        'learning_rate_init': Real(1e-4, 1e-1, prior='log-uniform')  # Initial learning rate\n",
    "    },\n",
    "    n_iter=20,\n",
    "    random_state=42,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    scoring='f1'\n",
    ")\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = BayesSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    {\n",
    "        'n_neighbors': Integer(1, 50),\n",
    "        'weights': Categorical(['uniform', 'distance']),\n",
    "        'algorithm': Categorical(['auto', 'ball_tree', 'kd_tree', 'brute']),\n",
    "        'leaf_size': Integer(10, 50),\n",
    "        'p': Integer(1, 2)  # 1 = Manhattan, 2 = Euclidean distance\n",
    "    },\n",
    "    n_iter=20,\n",
    "    random_state=42,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    scoring='f1'\n",
    ")\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_model = BayesSearchCV(\n",
    "    XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
    "    {\n",
    "        'n_estimators': Integer(50, 500),\n",
    "        'max_depth': Integer(3, 10),\n",
    "        'learning_rate': Real(0.01, 1.0, prior='log-uniform'),\n",
    "        'subsample': Real(0.5, 1.0, prior='uniform'),  # Fraction of samples used for fitting\n",
    "        'colsample_bytree': Real(0.5, 1.0, prior='uniform'),  # Fraction of features used per tree\n",
    "        'gamma': Real(1e-6, 5, prior='log-uniform'),  # Min loss reduction for split\n",
    "        'reg_alpha': Real(1e-5, 10, prior='log-uniform'),  # L1 regularization\n",
    "        'reg_lambda': Real(1e-5, 10, prior='log-uniform')  # L2 regularization\n",
    "    },\n",
    "    n_iter=20,\n",
    "    random_state=42,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    scoring='f1'\n",
    ")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = BayesSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    {\n",
    "        'n_estimators': Integer(50, 500),\n",
    "        'max_depth': Integer(5, 50),\n",
    "        'min_samples_split': Integer(2, 20),\n",
    "        'min_samples_leaf': Integer(1, 10),\n",
    "        'max_features': Categorical(['sqrt', 'log2', None]),  # Number of features to consider at each split\n",
    "        'bootstrap': Categorical([True, False]),\n",
    "        'criterion': Categorical(['gini', 'entropy'])\n",
    "    },\n",
    "    n_iter=20,\n",
    "    random_state=42,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    scoring='f1'\n",
    ")\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = BayesSearchCV(\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    {\n",
    "        'criterion': Categorical(['gini', 'entropy']),\n",
    "        'max_depth': Integer(3, 30),\n",
    "        'min_samples_split': Integer(2, 20),\n",
    "        'min_samples_leaf': Integer(1, 20),\n",
    "        'max_features': Categorical(['sqrt', 'log2', None]),\n",
    "        'ccp_alpha': Real(0.0, 0.1, prior='uniform')  # Cost-Complexity Pruning alpha\n",
    "    },\n",
    "    n_iter=20,\n",
    "    random_state=42,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    scoring='f1'\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = BayesSearchCV(\n",
    "    LogisticRegression(random_state=42, solver='saga', max_iter=5000),\n",
    "    {\n",
    "        'C': Real(1e-6, 1e+6, prior='log-uniform'),  # Inverse of regularization strength\n",
    "        'penalty': Categorical(['l1', 'l2', 'elasticnet']),\n",
    "        'l1_ratio': Real(0, 1, prior='uniform'),  # Only used if penalty='elasticnet'\n",
    "        'fit_intercept': Categorical([True, False])\n",
    "    },\n",
    "    n_iter=20,\n",
    "    random_state=42,\n",
    "    verbose=0,\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    scoring='f1'\n",
    ")"
   ],
   "id": "426f25920ade3a47"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def fit_and_evaluate(model, model_name, X_train, X_test, y_train, y_test, X_resampled, y_resampled):\n",
    "    print(f\"\\n{'=' * 40}\")\n",
    "    print(f\"Training {model_name}...\")\n",
    "    print(f\"{'=' * 40}\")\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    model_performance.append({\n",
    "        'Model': model_name,\n",
    "        'Best Score (CV)': model.best_score_,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Best Params': model.best_params_\n",
    "    })\n",
    "\n",
    "    print(f\"Best CV Score: {model.best_score_:.4f}\")\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix: {model_name}')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# all models in one dict with names\n",
    "models_dict = {\n",
    "    \"SVM\": svm_model,\n",
    "    \"MLP\": mlp_model,\n",
    "    \"KNN\": knn_model,\n",
    "    \"XGBoost\": xgb_model,\n",
    "    \"Random Forest\": rf_model,\n",
    "    \"Decision Tree\": dt_model,\n",
    "    \"Logistic Regression\": lr_model\n",
    "}\n",
    "\n",
    "model_performance = []\n",
    "\n",
    "for name, model in models_dict.items():\n",
    "    fit_and_evaluate(model, name, X_train_scaled, X_test_scaled, y_train, y_test, X_resampled, y_resampled)\n",
    "\n",
    "results_df = pd.DataFrame(model_performance)\n",
    "results_df = results_df.sort_values(by='F1 Score', ascending=False)\n",
    "\n",
    "# get best model and retrain\n",
    "print(\"training best model...\")\n",
    "best_model = models_dict[results_df[\"Model\"].iloc[0]]\n",
    "best_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"\\nModel Comparison Table:\")\n",
    "display(results_df)"
   ],
   "id": "e14927954f8ed995"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# un-normalise the data and try to find out which samples were misclassified\n",
    "train_predictions = best_model.predict(X_train_scaled)\n",
    "test_predictions = best_model.predict(X_test_scaled)\n",
    "\n",
    "indexed_train_predictions = y_train.reset_index()\n",
    "indexed_train_predictions[\"Prediction\"] = train_predictions\n",
    "indexed_train_predictions.index = indexed_train_predictions[\"index\"]\n",
    "indexed_train_predictions = indexed_train_predictions.drop([\"index\"], axis=1)\n",
    "\n",
    "indexed_test_predictions = y_test.reset_index()\n",
    "indexed_test_predictions[\"Prediction\"] = test_predictions\n",
    "indexed_test_predictions.index = indexed_test_predictions[\"index\"]\n",
    "indexed_test_predictions = indexed_test_predictions.drop([\"index\"], axis=1)\n",
    "\n",
    "predictions_to_be_appended = pd.concat([indexed_train_predictions, indexed_test_predictions], axis=0)\n",
    "predictions_to_be_appended[\"misclassified\"] = abs(\n",
    "    predictions_to_be_appended[\"Prediction\"] - predictions_to_be_appended[\"progression\"])\n",
    "predictions_to_be_appended = predictions_to_be_appended.drop([\"progression\"], axis=1)\n",
    "\n",
    "original_data_with_predictions = labels_X_all.join(predictions_to_be_appended)\n",
    "\n",
    "display(original_data_with_predictions[original_data_with_predictions[\"misclassified\"] == 1])"
   ],
   "id": "144f4c2db558d634"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sns.set_style(\"ticks\")\n",
    "sns.set_context(\"paper\", font_scale=1.4)\n",
    "\n",
    "prog_group = original_data_with_predictions[original_data_with_predictions[\"progression\"] == 1]\n",
    "no_prog_group = original_data_with_predictions[original_data_with_predictions[\"progression\"] == 0]\n",
    "\n",
    "feature_cols = [c for c in original_data_with_predictions.columns if c != \"progression\"]\n",
    "\n",
    "for col in feature_cols:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    if pd.api.types.is_numeric_dtype(original_data_with_predictions[col]):\n",
    "\n",
    "        sns.kdeplot(data=no_prog_group, x=col, fill=True,\n",
    "                    color='forestgreen', label='No Progression', alpha=0.3, linewidth=2)\n",
    "        sns.kdeplot(data=prog_group, x=col, fill=True,\n",
    "                    color='crimson', label='Progression', alpha=0.4, linewidth=2)\n",
    "\n",
    "        plt.ylabel('Density')\n",
    "        plt.legend()\n",
    "\n",
    "    else:\n",
    "        temp_df = original_data_with_predictions.groupby('progression')[col].value_counts(normalize=True).rename(\n",
    "            'proportion').reset_index()\n",
    "        temp_df['progression_label'] = temp_df['progression'].map({0: 'No Progression', 1: 'Progression'})\n",
    "\n",
    "        sns.barplot(data=temp_df, x=col, y='proportion', hue='progression_label',\n",
    "                    palette={'No Progression': 'forestgreen', 'Progression': 'crimson'}, edgecolor='black')\n",
    "\n",
    "        plt.ylabel('Proportion')\n",
    "        plt.legend(title=None)\n",
    "\n",
    "    plt.title(f'{col}')\n",
    "    plt.xlabel(col)\n",
    "\n",
    "    sns.despine()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "bdea246fd4620401"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "78f9c33240f2569b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "25c8af511c03b3a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7861333ac09d3197"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
